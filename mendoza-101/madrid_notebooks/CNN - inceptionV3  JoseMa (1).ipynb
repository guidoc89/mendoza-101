{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificacion de IDC con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias y Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hay muchas librerias que tal vez no estoy usando falta limpiar\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CyclicLR\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from glob import glob  #El módulo glob puede obtener la ruta completa de todos los archivos elegibles de acuerdo con la ruta especificada\n",
    "from skimage.io import imread\n",
    "from os import listdir\n",
    "\n",
    "import time  #contiene una serie de funciones relacionadas con la medición del tiempo\n",
    "import copy  #permite crear copias de distintos objetos de Python\n",
    "from tqdm import tqdm_notebook as tqdm  #Instantly make your loops show a smart progress meter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from imblearn.metrics import sensitivity_score, specificity_score\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training = False\n",
    "retrain = False\n",
    "find_learning_rate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos el Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui he cargado a mano una parte, por lo que es muy prbable que este sesgado y esto dificulte el aprendizaje, lo primero que hay que hacer es generar un codigo que extraiga una muestra aleatorea.\n",
    "\n",
    "\n",
    "JOSEMA: Cambie la url del dataset para mi pc, tu tendras que hacer lo mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = listdir(\"C:/Users/juanS/OneDrive/Escritorio/Master IMF/TFM/TFM DS/Data Set/IDC_regular_ps50_idx5\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10253',\n",
       " '10254',\n",
       " '10255',\n",
       " '10256',\n",
       " '10257',\n",
       " '10258',\n",
       " '10259',\n",
       " '10260',\n",
       " '10261',\n",
       " '10262']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/juanS/OneDrive/Escritorio/Master IMF/TFM/TFM DS/Data Set/IDC_regular_ps50_idx5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamentablemente, el número de pacientes es bastante pequeño, por lo que se debe prestar mucha atención al sobreajuste de los datos.\n",
    "\n",
    "Para contrarestar esta desventaja, procedemos a realizar cortes de 40x40 sobre la imagen del paciente para de esta forma aumentar eficientemente el numero de imagenes que disponemos para nuestro algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + \"/\" + patient_id\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        total_images += len(subfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277524"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro algoritmo debe decidir si un parche de imagen contiene IDC o no. \n",
    "No todo el corte de tejido del paciente, sino los parches individuales, es decir que si un parche o corte posee IDC entonces ese usuario posee IDC.\n",
    "\n",
    "**IDC (+) se considera Cancer**\n",
    "\n",
    "**IDC (-) Se considera normal**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sería importante **almacenar la ruta de cada imagen**. De esta manera evitamos almacenar cada pixel de cada imagen. \n",
    "Si almacenamos el path, podemos cargar lotes de imágenes por 'paciente_id' y el 'target'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el Data Set con el que experimentaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                               path target\n",
       "0      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...      0\n",
       "1      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...      0\n",
       "2      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...      0\n",
       "3      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...      0\n",
       "4      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(index=np.arange(0, total_images),\n",
    "                    columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + \"/\" + patient_id\n",
    "    for c in [0, 1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marco de datos\n",
    "\n",
    "Tenemos que **extraer todas las coordenadas de los parches de imagen** que están almacenados en los nombres de las imágenes. **Entonces podemos usar las coordenadas para reconstruir todo el tejido mamario de una paciente**. De esta manera, también **podemos explorar cómo se ve el tejido enfermo en comparación con los sanos**. Para simplificar esta tarea, escribamos un método que tome un paciente y genere un marco de datos con coordenadas y objetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(df):\n",
    "    coord = df.path.str.rsplit(\"_\", n=4, expand=True)\n",
    "    coord = coord.drop([0, 1, 4], axis=1)\n",
    "    coord = coord.rename({2: \"x\", 3: \"y\"}, axis=1)\n",
    "    coord.loc[:, \"x\"] = coord.loc[:,\n",
    "                                  \"x\"].str.replace(\"x\", \"\",\n",
    "                                                   case=False).astype(np.int)\n",
    "    coord.loc[:, \"y\"] = coord.loc[:,\n",
    "                                  \"y\"].str.replace(\"y\", \"\",\n",
    "                                                   case=False).astype(np.int)\n",
    "    df.loc[:, \"x\"] = coord.x.values\n",
    "    df.loc[:, \"y\"] = coord.y.values\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_cancer_dataframe(patient_id, cancer_id):\n",
    "    path = base_path + \"/\" + patient_id + \"/\" + cancer_id\n",
    "    files = listdir(path)\n",
    "    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n",
    "    path_names = path + \"/\" + dataframe.filename.values\n",
    "    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n",
    "    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n",
    "    dataframe.loc[:, \"path\"] = path_names\n",
    "    dataframe = dataframe.drop([0, 1, 4], axis=1)\n",
    "    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n",
    "    dataframe.loc[:, \"x\"] = dataframe.loc[:, \"x\"].str.replace(\n",
    "        \"x\", \"\", case=False).astype(np.int)\n",
    "    dataframe.loc[:, \"y\"] = dataframe.loc[:, \"y\"].str.replace(\n",
    "        \"y\", \"\", case=False).astype(np.int)\n",
    "    return dataframe\n",
    "\n",
    "def get_patient_dataframe(patient_id):\n",
    "    df_0 = get_cancer_dataframe(patient_id, \"0\")\n",
    "    df_1 = get_cancer_dataframe(patient_id, \"1\")\n",
    "    patient_df = df_0.append(df_1)\n",
    "    return patient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del tejido mamario \n",
    "\n",
    "Esta parte es un poco complicada, tenemos que extraer todas las coordenadas de los parches de imagen que están almacenados en los nombres de las imágenes.\n",
    "\n",
    "Luego, podemos usar las coordenadas para reconstruir todo el tejido mamario de una paciente. De esta manera también podemos explorar cómo se ve el tejido enfermo en comparación con los sanos. \n",
    "\n",
    "**Para simplificar esta tarea, escribimos un método que tome a un paciente y dé como resultado un marco de datos con coordenadas y objetivos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1051</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1101</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1201</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x     y  target                                               path\n",
       "0  1001  1001       0  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...\n",
       "1  1001  1051       0  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...\n",
       "2  1001  1101       0  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...\n",
       "3  1001  1151       0  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...\n",
       "4  1001  1201       0  C:/Users/juanS/OneDrive/Escritorio/Master IMF/..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_patient_dataframe(data.patient_id.values[0])\n",
    "example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora tenemos las coordenadas de cada parche, su ruta para cargar la imagen y su información de destino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las imágenes del tejido mamario \n",
    "\n",
    "Ahora es el momento de ir un paso más profundo con nuestra EDA.\n",
    "\n",
    "Dadas las coordenadas de los parches de imagen, podríamos intentar reconstruir la imagen de tejido completo (no solo los objetivos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the machine learning workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # tamaño de muestra (lote)\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "OUTPUT_PATH = \"\"\n",
    "# MODEL_PATH = \"C:/Users/juanS/OneDrive/Escritorio/Master IMF/TFM/TFM DS/Data Set/archive\"\n",
    "# LOSSES_PATH = \"C:/Users/juanS/OneDrive/Escritorio/Master IMF/TFM/TFM DS/Data Set/archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que los resultados sean replicables\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuo trabajando sobre el DF, no el que usamos para la visualizacion de todo el tejido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target = data.target.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target = data.target.astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 277524 entries, 0 to 277523\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   patient_id  277524 non-null  object\n",
      " 1   path        277524 non-null  object\n",
      " 2   target      277524 non-null  bool  \n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, asigno el 80% del conjunto de datos para entrenamiento y el otro 20% para pruebas. En este caso, como se mencionó anteriormente, la validación es crucial. Por lo tanto, asignaré el 70% para el entrenamiento del modelo , el 15% para las pruebas y el 15% para la validación.\n",
    "\n",
    "\n",
    "JOSEMA: En la siguiente linea me quede con los primeros 50 pacientes, ahi puedes modificar segun la cantidad que quieras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data.patient_id.unique()[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, sub_test_ids = train_test_split(patients,\n",
    "                                           test_size=0.3,\n",
    "                                           random_state=0)\n",
    "test_ids, dev_ids = train_test_split(sub_test_ids,\n",
    "                                     test_size=0.5,\n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we can't stratify on the targets as we are splitting on patient ids. If we would like to include some target information we would need to create a feature that allows us to generate some balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0 16.0 14.000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(train_ids) / patients.shape[0] * 100,\n",
    "    len(dev_ids) / patients.shape[0] * 100,\n",
    "    len(test_ids) / patients.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 8 7\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(dev_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set is used for determining the parameters of the model\n",
    "\n",
    "train_df = data.loc[data.patient_id.isin(train_ids), :].copy()\n",
    "test_df = data.loc[data.patient_id.isin(test_ids), :].copy()\n",
    "dev_df = data.loc[data.patient_id.isin(dev_ids), :].copy()\n",
    "\n",
    "# extract cords esta definida mas arriba\n",
    "train_df = extract_coords(train_df)\n",
    "test_df = extract_coords(test_df)\n",
    "dev_df = extract_coords(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1001</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1001</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1001</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10253</td>\n",
       "      <td>C:/Users/juanS/OneDrive/Escritorio/Master IMF/...</td>\n",
       "      <td>False</td>\n",
       "      <td>1001</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                               path  target     x  \\\n",
       "0      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...   False  1001   \n",
       "1      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...   False  1001   \n",
       "2      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...   False  1001   \n",
       "3      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...   False  1001   \n",
       "4      10253  C:/Users/juanS/OneDrive/Escritorio/Master IMF/...   False  1001   \n",
       "\n",
       "      y  \n",
       "0  1001  \n",
       "1  1051  \n",
       "2  1101  \n",
       "3  1151  \n",
       "4  1201  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 44570\n",
      "Number of validation samples: 8755\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "#train_metadata_filename = \"train.csv\"\n",
    "#valid_metadata_filename = \"valid.csv\"\n",
    "# load CSV files as DataFrames\n",
    "#df_train = pd.read_csv(train_metadata_filename)\n",
    "#df_valid = pd.read_csv(valid_metadata_filename)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "n_training_samples = len(train_df)\n",
    "n_validation_samples = len(dev_df)\n",
    "print(\"Number of training samples:\", n_training_samples)\n",
    "print(\"Number of validation samples:\", n_validation_samples)\n",
    "train_ds1 = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_df[\"path\"], train_df[\"target\"]))\n",
    "valid_ds1 = tf.data.Dataset.from_tensor_slices(\n",
    "    (dev_df[\"path\"], dev_df[\"target\"]))\n",
    "\n",
    "## from_tensor_slices() method, we can get the slices of an array in the form of objects by using tf. data -- aplica una transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE \n",
    "\n",
    "JOSEMA: annadi el filtro clahe que  supuestamente elimina el ruido en las imagenes\n",
    "\n",
    "Se utiliza para eliminar el ruido en la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-d07777a756dc>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-d07777a756dc>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip install tf_clahe\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pip install cv2\n",
    "#pip install tf_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#import tf_clahe\n",
    "#import tf_clahe\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_contrast_image_using_clahe(bgr_image: np.array) -> np.array:\n",
    "    hsv = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_planes = cv2.split(hsv)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    hsv_planes = (hsv_planes[0], hsv_planes[1], clahe.apply(hsv_planes[2]))\n",
    "    hsv = cv2.merge(hsv_planes)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "import tf_clahe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "JOSEMA: en decode_img annadi lo del clahe que mencionaba arriba y normalize la imagen (si lo quieres quitar comentas las lineas que dicen JOSEMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (299, 299, 3)\n",
      "Label: False\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3) # canales rgb\n",
    "    img = tf_clahe.clahe(img)  ## JOSEMA\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [299, 299]) ## este tamaño es requerido por la red inception V3\n",
    "    # resize the image to the desired size.\n",
    "    return normalization_layer(img)  #JOSEMA\n",
    "    # return normalization_layer(img)  \n",
    "\n",
    "\n",
    "\n",
    "def process_path(filepath, label):\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "valid_ds = valid_ds1.map(process_path)  # map procesa una transformacion (process_path) al objeto iterable\n",
    "train_ds = train_ds1.map(process_path)\n",
    "# test_ds = test_ds\n",
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El código anterior usa el método map() para ejecutar la función process_path() en cada muestra en ambos conjuntos, básicamente cargará las imágenes, decodificará el formato de la imagen, convertirá los píxeles de la imagen para que estén en el rango [0, 1] y cambiará el tamaño a (299, 299, 3), luego tomamos una imagen e imprimimos su forma:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionV3 requiere un formato (299, 299) para ser procesado, por eso redimensionamos la imagen a este tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((299, 299, 3), ()), types: (tf.float32, tf.bool)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "optimizer = \"adam\"\n",
    "\n",
    "\n",
    "def prepare_for_training(ds,\n",
    "                         cache=True,\n",
    "                         batch_size=64,\n",
    "                         shuffle_buffer_size=100):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "    # shuffle the dataset\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    # Repeat forever\n",
    "    #ds = ds.repeat()\n",
    "    # split to batches\n",
    "    ds = ds.batch(batch_size)\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "valid_ds = prepare_for_training(valid_ds,\n",
    "                                batch_size=batch_size,\n",
    "                                cache=\"valid-cached-data\")\n",
    "train_ds = prepare_for_training(train_ds,\n",
    "                                batch_size=batch_size,\n",
    "                                cache=\"train-cached-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui hacemos un poco de ingenieria para preparar los datos para el entrenamiento.\n",
    "\n",
    "* Batch mejora el aprendizaje, tomando muestras aleatoreas. Esto impide que aprenda de manera sistematica.\n",
    "* cache(): Since we're making too many calculations on each set, we used cache() method to save our preprocessed dataset into a local cache file, this will only preprocess it the very first time (in the first epoch during training).\n",
    "* shuffle(): To basically shuffle the dataset, so the samples are in random order.\n",
    "* repeat(): Every time we iterate over the dataset, it'll keep generating samples for us repeatedly, this will help us during the training.\n",
    "* batch(): We batch our dataset into 64 or 32 samples per training step.\n",
    "* prefetch(): This will enable us to fetch batches in the background while the model is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estas clases las definimos para asignarlas como titulos en la siguiente grafica\n",
    "class_names = [\"benign\", \"malignant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(tf.keras.layers.Layer):\n",
    "    \n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch = next(iter(valid_ds))\n",
    "\n",
    "\n",
    "def show_batch(batch):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(batch[0][n])\n",
    "        plt.title(class_names[batch[1][n].numpy()].title())\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "show_batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOSEMA: Si normalizas antes as imagenes ya no seran visibles, porque tendran valores entre 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation, flip horizontal / verticaly resize. \n",
    "\n",
    "The simplest transformations we can do for each image are:\n",
    "\n",
    "* resizing the images to the desired input shape, performing horizontal and vertical flips.\n",
    "\n",
    "* Furthermore we need to create a dataset that loads an image patch of a patient, converts it to RGB, performs the augmentation if it's desired and returns the image, the target, the patient id and the image coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
    "                                                 input_shape=(299,                                                           299,\n",
    "                                                               3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la estructura del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOSEMA: Desde aqui hasta que llegue al error hice lo de InceptionV3 guiandome por la doc y lo que ya tenias, el error me dio porque la cnn guarda en cache y se me lleno el disco duro pero a ti te deberia servir. Tiene dos neuronas de salida pero si quieres lo cambias y pones la sigmoid con 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "#import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "model = hub.load(\"C:/Users/juanS/-- Trabajos Master --/TFM (ds)/tf2-preview_inception_v3_classification_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = hub.KerasLayer(hub.load(\"C:/Users/juanS/-- Trabajos Master --/TFM (ds)/tf2-preview_inception_v3_classification_4\"), output_shape=[2048], trainable=False)\n",
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    inception_v3,\n",
    "    input_shape=(299, 299, 3),\n",
    "    trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_batch = feature_extractor_layer(image_batch)\n",
    "#print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 1001)              23853833  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2004      \n",
      "=================================================================\n",
      "Total params: 23,855,837\n",
      "Trainable params: 2,004\n",
      "Non-trainable params: 23,853,833\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1) # Enable histogram computation for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n",
      "\n",
      "Got `type(handle)`: <class 'tensorflow_hub.keras_layer.KerasLayer'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Can only generate a valid config for `hub.KerasLayer(handle, ...)`that uses a string `handle`.\n",
      "\n",
      "Got `type(handle)`: <class 'tensorflow_hub.keras_layer.KerasLayer'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "697/697 [==============================] - 2308s 3s/step - loss: 0.8252 - acc: 0.8273 - val_loss: 0.5559 - val_acc: 0.7540\n",
      "Epoch 2/10\n",
      "697/697 [==============================] - 2391s 3s/step - loss: 0.7342 - acc: 0.8425 - val_loss: 0.5637 - val_acc: 0.7540\n",
      "Epoch 3/10\n",
      "697/697 [==============================] - 2350s 3s/step - loss: 0.7120 - acc: 0.8458 - val_loss: 0.5830 - val_acc: 0.7540\n",
      "Epoch 4/10\n",
      "697/697 [==============================] - 2314s 3s/step - loss: 0.7036 - acc: 0.8480 - val_loss: 0.6055 - val_acc: 0.7540\n",
      "Epoch 5/10\n",
      "697/697 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.8499 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-77180180aa69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = model.fit(train_ds,\n\u001b[0m\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=valid_ds,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## //////////////////////////////////////////////\n",
    "\n",
    "JOSEMA: ya de aqui para abajo es lo mismo que tenias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "# load testing set\n",
    "\n",
    "n_testing_samples = len(test_df)\n",
    "\n",
    "print(\"Number of testing samples:\", n_testing_samples)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_df[\"path\"], test_df[\"target\"]))\n",
    "\n",
    "\n",
    "\n",
    "def prepare_for_testing(ds, cache=True, shuffle_buffer_size=100):\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  return ds\n",
    "\n",
    "test_ds = test_ds.map(process_path)\n",
    "test_ds = prepare_for_testing(test_ds, cache=\"test-cached-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert testing set to numpy array to fit in memory (don't do that when testing\n",
    "# set is too large)\n",
    "y_test = np.zeros((n_testing_samples,))\n",
    "X_test = np.zeros((n_testing_samples, 299, 299, 3))\n",
    "for i, (img, label) in enumerate(test_ds.take(n_testing_samples)):\n",
    "    print(img.shape, label.shape)\n",
    "    X_test[i] = img\n",
    "    y_test[i] = label.numpy()\n",
    "\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating the model...\")\n",
    "loss, accuracy = m.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss, \"  Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy no es una buena medida ya que los datos estan desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(threshold=None):\n",
    "  \"\"\"\n",
    "  Returns predictions for binary classification given `threshold`\n",
    "  For instance, if threshold is 0.3, then it'll output 1 (malignant) for that sample if\n",
    "  the probability of 1 is 30% or more (instead of 50%)\n",
    "  \"\"\"\n",
    "  y_pred = m.predict(X_test)\n",
    "  if not threshold:\n",
    "    threshold = 0.5\n",
    "  result = np.zeros((n_testing_samples,))\n",
    "  for i in range(n_testing_samples):\n",
    "    # test melanoma probability\n",
    "    if y_pred[i][0] >= threshold:\n",
    "      result[i] = 1\n",
    "    # else, it's 0 (benign)\n",
    "  return result\n",
    "\n",
    "threshold = 0.23\n",
    "# get predictions with 23% threshold\n",
    "# which means if the model is 23% sure or more that is malignant,\n",
    "# it's assigned as malignant, otherwise it's benign\n",
    "y_pred = get_predictions(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "  cmn = confusion_matrix(y_test, y_pred)\n",
    "  # Normalise\n",
    "  cmn = cmn.astype('float') / cmn.sum(axis=1)[:, np.newaxis]\n",
    "  # print it\n",
    "  print(cmn)\n",
    "  fig, ax = plt.subplots(figsize=(10,10))\n",
    "  sns.heatmap(cmn, annot=True, fmt='.2f', \n",
    "              xticklabels=[f\"pred_{c}\" for c in class_names], \n",
    "              yticklabels=[f\"true_{c}\" for c in class_names],\n",
    "              cmap=\"Blues\"\n",
    "              )\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  # plot the resulting confusion matrix\n",
    "  plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = sensitivity_score(y_test, y_pred)\n",
    "specificity = specificity_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"IDC precision:\", precision)\n",
    "print(\"IDC recall:\", recall)\n",
    "print(\"IDC Sensitivity:\", sensitivity)\n",
    "print(\"IDC Specificity:\", specificity)\n",
    "print(\"IDC f1:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Precision nos da la calidad de la predicción: ¿qué porcentaje de los que hemos dicho que son la clase positiva, en realidad lo son?\n",
    "\n",
    "* Recall nos da la cantidad: ¿qué porcentaje de la clase positiva hemos sido capaces de identificar?\n",
    "\n",
    "* F1 combina Precision y Recall en una sola medida\n",
    "\n",
    "* La Matriz de Confusión indica qué tipos de errores se cometen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy Cost Function\n",
    "For batch gradient descent we need to adjust the Binary Cross Entropy(BCE) Loss function to accommodate not just one example but all the examples in a batch. This adjusted Loss function is called the Cost function(also represented by the letter J in neural network literature and some times also called the objective function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function plots the ROC curves and provides the scores.\n",
    "    \"\"\"\n",
    "    # prepare for figure\n",
    "    plt.figure()\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    # obtain ROC AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # print score\n",
    "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "    # plot ROC curve\n",
    "    plt.plot(fpr, tpr, color=\"blue\", lw=2,\n",
    "                label='ROC curve (area = {f:.2f})'.format(d=1, f=roc_auc))\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_auc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
